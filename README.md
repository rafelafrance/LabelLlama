# Label Llama![CI](https://github.com/rafelafrance/LabelLlama/workflows/CI/badge.svg)
## From 30,000 feet:
Extract information from labels on images of herbarium sheets.

There are 3 main steps:
1. Find all labels on the herbarium sheet.
2. OCR the text on the labels.
3. Extract information from the OCRed text.

Of course things are a bit more complicated than just those 3 steps.

### Given images of herbarium sheets
![Herbarium Sheet](assets/sheet.jpg)

### Find labels on the sheet
![Herbarium Labels](assets/show_labels.png)

In this example labels outlined in orange are considered scientifically interesting and the teal labels can be ignored.

### OCR text in the labels
![OCRed Text](assets/show_ocr_text.png)

OCRed text from the label on the lower right of the sheet.

### Annotate text in the labels
![text.png|Label Text](assets/text.png)

This is clearly from another sheet and label. The colors indicate text matched to fields.

### Output text to structured fields
![Label Traits](assets/traits.png)

The text is formatted and placed into named fields using the Darwin Core format.

## Pipeline overview

1. `outline_labels.py`: This is a GUI script used to mark labels on specimen images. You draw colored boxes around labels on the sheet. The colors correspond to the type of label.
   1. I use this to generate training data for a "label finder" model.
   2. I also use this to generate labels for the rest of the pipeline.
   3. TODO:
      1. Handle shrinking sheet images if the width is too small. I already do this for height.
      2. Resize canvas and images when the screen is resized. Adding scroll bars would be another option.
      3. Add a fast-forward button that takes you to the first unannotated sheet. Hitting it multiple times takes you to the next unannotated sheet.
      4. General GUI improvements to make it look better. Frames and styling.
      5. Maybe add keyboard shortcuts?
      6. Improve radio button selection visibility.
      7. Add mouse-over hints for the labels?

    ![outline_labels](assets/outline_labels.png)

   In this figure of a herbarium sheet, I outlined the typewritten labels in red and handwritten labels in blue. I ignored envelopes, barcodes, etc.
2. `label_finder_input.py` TBD. Format the output of `outline_labels.py` for whatever model you're using for the label finder.
3. Label finder model. TBD.
4. `label_finder_output.py` TBD. Format the output of the label finder model into something the `cutout_labels.py` script can use.
5. `modify_outlined_labels.py` I use this script to update data in JSON data generated above in step one:
   1. If you move the directory of the original specimen images.
   2. I deleted the JSON file generated by `outline_labels.py`, but if I still have the label images themselves generated by `cutout_labels.py` I can regenerate the JSON file.
6. `cutout_labels.py` This takes the output from `outline_labels.py` and generates images of the labels themselves.
7. OCR script. Not written by me. I am currently using `olmOCR`. If you use another OCR model you will have to format its output.
   1. `conda activate olmocr`
   2. `python -m olmocr.pipeline path/to/<workspace> --pdfs path/to/<label images>/*.jpg`
8. `format_ocr_output.py` Convert OCR output into LabelLlama format.
9. `run_lm.py` I use this script in 2 places. Here it is used to bootstrap annotation training data. The language models can help generate training data even without prior training. I will definitely need to run the generated data through the rest of the pipeline, but it helps.
10. `annotate_fields.py` A GUI script used to annotate label text that get used for training and scoring.
    1. TODO:
        1. General improvements to the GUI.
        2. Add keyboard shortcuts?
        3. Improve radio button selection visibility.
        4. Add more information for the mouse-over popups.
        5. Improve error reporting.

    ![annotate_fields](assets/annotate_fields.png)

11. `modify_annotated_fields.py` Used to add, delete, modify the annotated fields.
12. `train_lm.py`
13. `score_lm.py`
14. `show_lm_results.py` Show what the trained language model produces.
15. `run_lm.py` Reprise. Run the language model for inference.
